package mypackage;

import java.io.IOException;
import java.util.StringTokenizer;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapred.MapReduceBase;
import org.apache.hadoop.mapred.OutputCollector;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Mapper.Context;
import org.apache.hadoop.mapreduce.lib.input.FileSplit;

public class MapperTest extends Mapper<Object, Text, Text, Text>{
	private final static Text word = new Text();
    private final static Text location = new Text();
    
    @Override
    public void map(Object key, Text value,Context collector) throws InterruptedException{
    	
    	FileSplit fileSplit = (FileSplit)collector.getInputSplit();
        String fileName = fileSplit.getPath().getName();
        location.set(fileName);

        String line = value.toString();
        StringTokenizer itr = new StringTokenizer(line.toLowerCase());
        while (itr.hasMoreTokens()) {
          word.set(itr.nextToken());
          try {
			collector.write(word, location);
		} catch (IOException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
    }

}
} 
